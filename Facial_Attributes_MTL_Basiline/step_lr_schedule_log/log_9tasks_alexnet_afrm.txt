Namespace(batchSize=32, filename='9tasks_alexnet_afrm', gpu='0', lr=0.001, lr_scheduler=None, model='alexnet', nepoch=10, pretrained=False, workers=2)
False
Final Saved Model Path: 9tasks_alexnet_afrm

Train epoch: 0
[0/10][0/5087] loss: 1.0037
[0/10][100/5087] loss: 0.5635
[0/10][200/5087] loss: 0.6928
[0/10][300/5087] loss: 0.6314
[0/10][400/5087] loss: 0.6301
[0/10][500/5087] loss: 0.6138
[0/10][600/5087] loss: 0.6240
[0/10][700/5087] loss: 0.5663
[0/10][800/5087] loss: 0.5964
[0/10][900/5087] loss: 0.5402
[0/10][1000/5087] loss: 0.6158
[0/10][1100/5087] loss: 0.5600
[0/10][1200/5087] loss: 0.4399
[0/10][1300/5087] loss: 0.5063
[0/10][1400/5087] loss: 0.4742
[0/10][1500/5087] loss: 0.5032
[0/10][1600/5087] loss: 0.5228
[0/10][1700/5087] loss: 0.4950
[0/10][1800/5087] loss: 0.4691
[0/10][1900/5087] loss: 0.5764
[0/10][2000/5087] loss: 0.5493
[0/10][2100/5087] loss: 0.4711
[0/10][2200/5087] loss: 0.4885
[0/10][2300/5087] loss: 0.5392
[0/10][2400/5087] loss: 0.5044
[0/10][2500/5087] loss: 0.4926
[0/10][2600/5087] loss: 0.5258
[0/10][2700/5087] loss: 0.4592
[0/10][2800/5087] loss: 0.5239
[0/10][2900/5087] loss: 0.5907
[0/10][3000/5087] loss: 0.4563
[0/10][3100/5087] loss: 0.5752
[0/10][3200/5087] loss: 0.4643
[0/10][3300/5087] loss: 0.5196
[0/10][3400/5087] loss: 0.5170
[0/10][3500/5087] loss: 0.4887
[0/10][3600/5087] loss: 0.4433
[0/10][3700/5087] loss: 0.5319
[0/10][3800/5087] loss: 0.4885
[0/10][3900/5087] loss: 0.4139
[0/10][4000/5087] loss: 0.4844
[0/10][4100/5087] loss: 0.4964
[0/10][4200/5087] loss: 0.3852
[0/10][4300/5087] loss: 0.4261
[0/10][4400/5087] loss: 0.5236
[0/10][4500/5087] loss: 0.3920
[0/10][4600/5087] loss: 0.4367
[0/10][4700/5087] loss: 0.4832
[0/10][4800/5087] loss: 0.4460
[0/10][4900/5087] loss: 0.4678
[0/10][5000/5087] loss: 0.3556

Test epoch: 0
tensor([0.8829, 0.7914, 0.7624, 0.7990, 0.9793, 0.9339, 0.8451, 0.7912, 0.8859])
tensor(0.8523)

Train epoch: 1
[1/10][0/5087] loss: 0.4295
[1/10][100/5087] loss: 0.5241
[1/10][200/5087] loss: 0.3727
[1/10][300/5087] loss: 0.3870
[1/10][400/5087] loss: 0.3926
[1/10][500/5087] loss: 0.4313
[1/10][600/5087] loss: 0.4242
[1/10][700/5087] loss: 0.3964
[1/10][800/5087] loss: 0.4167
[1/10][900/5087] loss: 0.4491
[1/10][1000/5087] loss: 0.3836
[1/10][1100/5087] loss: 0.3953
[1/10][1200/5087] loss: 0.4275
[1/10][1300/5087] loss: 0.4590
[1/10][1400/5087] loss: 0.4799
[1/10][1500/5087] loss: 0.4636
[1/10][1600/5087] loss: 0.4231
[1/10][1700/5087] loss: 0.4302
[1/10][1800/5087] loss: 0.4634
[1/10][1900/5087] loss: 0.4597
[1/10][2000/5087] loss: 0.4428
[1/10][2100/5087] loss: 0.4310
[1/10][2200/5087] loss: 0.3960
[1/10][2300/5087] loss: 0.4379
[1/10][2400/5087] loss: 0.4111
[1/10][2500/5087] loss: 0.3188
[1/10][2600/5087] loss: 0.4182
[1/10][2700/5087] loss: 0.4322
[1/10][2800/5087] loss: 0.5630
[1/10][2900/5087] loss: 0.3874
[1/10][3000/5087] loss: 0.4242
[1/10][3100/5087] loss: 0.4712
[1/10][3200/5087] loss: 0.3763
[1/10][3300/5087] loss: 0.4146
[1/10][3400/5087] loss: 0.4616
[1/10][3500/5087] loss: 0.4550
[1/10][3600/5087] loss: 0.4188
[1/10][3700/5087] loss: 0.4633
[1/10][3800/5087] loss: 0.4207
[1/10][3900/5087] loss: 0.3929
[1/10][4000/5087] loss: 0.4715
[1/10][4100/5087] loss: 0.4129
[1/10][4200/5087] loss: 0.3471
[1/10][4300/5087] loss: 0.4558
[1/10][4400/5087] loss: 0.4117
[1/10][4500/5087] loss: 0.3888
[1/10][4600/5087] loss: 0.3838
[1/10][4700/5087] loss: 0.4848
[1/10][4800/5087] loss: 0.3970
[1/10][4900/5087] loss: 0.3294
[1/10][5000/5087] loss: 0.4549

Test epoch: 1
tensor([0.8879, 0.8276, 0.7747, 0.8173, 0.9793, 0.9451, 0.8540, 0.8069, 0.8937])
tensor(0.8652)

Train epoch: 2
[2/10][0/5087] loss: 0.4696
[2/10][100/5087] loss: 0.3785
[2/10][200/5087] loss: 0.4422
[2/10][300/5087] loss: 0.3434
[2/10][400/5087] loss: 0.3935
[2/10][500/5087] loss: 0.3293
[2/10][600/5087] loss: 0.3920
[2/10][700/5087] loss: 0.3685
[2/10][800/5087] loss: 0.3914
[2/10][900/5087] loss: 0.4345
[2/10][1000/5087] loss: 0.4640
[2/10][1100/5087] loss: 0.4009
[2/10][1200/5087] loss: 0.4601
[2/10][1300/5087] loss: 0.3632
[2/10][1400/5087] loss: 0.3969
[2/10][1500/5087] loss: 0.3894
[2/10][1600/5087] loss: 0.3887
[2/10][1700/5087] loss: 0.4463
[2/10][1800/5087] loss: 0.3776
[2/10][1900/5087] loss: 0.3613
[2/10][2000/5087] loss: 0.4461
[2/10][2100/5087] loss: 0.3742
[2/10][2200/5087] loss: 0.3861
[2/10][2300/5087] loss: 0.4512
[2/10][2400/5087] loss: 0.3821
[2/10][2500/5087] loss: 0.4708
[2/10][2600/5087] loss: 0.3673
[2/10][2700/5087] loss: 0.4172
[2/10][2800/5087] loss: 0.4041
[2/10][2900/5087] loss: 0.3511
[2/10][3000/5087] loss: 0.3591
[2/10][3100/5087] loss: 0.3876
[2/10][3200/5087] loss: 0.4015
[2/10][3300/5087] loss: 0.4606
[2/10][3400/5087] loss: 0.3933
[2/10][3500/5087] loss: 0.3952
[2/10][3600/5087] loss: 0.4254
[2/10][3700/5087] loss: 0.3740
[2/10][3800/5087] loss: 0.3439
[2/10][3900/5087] loss: 0.4033
[2/10][4000/5087] loss: 0.3610
[2/10][4100/5087] loss: 0.4389
[2/10][4200/5087] loss: 0.3622
[2/10][4300/5087] loss: 0.3869
[2/10][4400/5087] loss: 0.3419
[2/10][4500/5087] loss: 0.3747
[2/10][4600/5087] loss: 0.4698
[2/10][4700/5087] loss: 0.4151
[2/10][4800/5087] loss: 0.4345
[2/10][4900/5087] loss: 0.4227
[2/10][5000/5087] loss: 0.3884

Test epoch: 2
tensor([0.8934, 0.8373, 0.7874, 0.8199, 0.9793, 0.9526, 0.8554, 0.8091, 0.9016])
tensor(0.8707)

Train epoch: 3
[3/10][0/5087] loss: 0.4611
[3/10][100/5087] loss: 0.4466
[3/10][200/5087] loss: 0.4460
[3/10][300/5087] loss: 0.3842
[3/10][400/5087] loss: 0.4479
[3/10][500/5087] loss: 0.2974
[3/10][600/5087] loss: 0.3716
[3/10][700/5087] loss: 0.3332
[3/10][800/5087] loss: 0.3652
[3/10][900/5087] loss: 0.3791
[3/10][1000/5087] loss: 0.4317
[3/10][1100/5087] loss: 0.3855
[3/10][1200/5087] loss: 0.4277
[3/10][1300/5087] loss: 0.3970
[3/10][1400/5087] loss: 0.4406
[3/10][1500/5087] loss: 0.3858
[3/10][1600/5087] loss: 0.4377
[3/10][1700/5087] loss: 0.3574
[3/10][1800/5087] loss: 0.4708
[3/10][1900/5087] loss: 0.4076
[3/10][2000/5087] loss: 0.3524
[3/10][2100/5087] loss: 0.4633
[3/10][2200/5087] loss: 0.4002
[3/10][2300/5087] loss: 0.3813
[3/10][2400/5087] loss: 0.3988
[3/10][2500/5087] loss: 0.5239
[3/10][2600/5087] loss: 0.3995
[3/10][2700/5087] loss: 0.4148
[3/10][2800/5087] loss: 0.3951
[3/10][2900/5087] loss: 0.4030
[3/10][3000/5087] loss: 0.3025
[3/10][3100/5087] loss: 0.4020
[3/10][3200/5087] loss: 0.3548
[3/10][3300/5087] loss: 0.3973
[3/10][3400/5087] loss: 0.4792
[3/10][3500/5087] loss: 0.3796
[3/10][3600/5087] loss: 0.3395
[3/10][3700/5087] loss: 0.3869
[3/10][3800/5087] loss: 0.4746
[3/10][3900/5087] loss: 0.4543
[3/10][4000/5087] loss: 0.3845
[3/10][4100/5087] loss: 0.3718
[3/10][4200/5087] loss: 0.4397
[3/10][4300/5087] loss: 0.3975
[3/10][4400/5087] loss: 0.3904
[3/10][4500/5087] loss: 0.4571
[3/10][4600/5087] loss: 0.3950
[3/10][4700/5087] loss: 0.3804
[3/10][4800/5087] loss: 0.3870
[3/10][4900/5087] loss: 0.3202
[3/10][5000/5087] loss: 0.3703

Test epoch: 3
tensor([0.8955, 0.8418, 0.7894, 0.8230, 0.9793, 0.9529, 0.8561, 0.8115, 0.8971])
tensor(0.8718)

Train epoch: 4
[4/10][0/5087] loss: 0.3766
[4/10][100/5087] loss: 0.3720
[4/10][200/5087] loss: 0.3604
[4/10][300/5087] loss: 0.3625
[4/10][400/5087] loss: 0.3693
[4/10][500/5087] loss: 0.4318
[4/10][600/5087] loss: 0.4815
[4/10][700/5087] loss: 0.3740
[4/10][800/5087] loss: 0.4306
[4/10][900/5087] loss: 0.4167
[4/10][1000/5087] loss: 0.3808
[4/10][1100/5087] loss: 0.3567
[4/10][1200/5087] loss: 0.3783
[4/10][1300/5087] loss: 0.4194
[4/10][1400/5087] loss: 0.3436
[4/10][1500/5087] loss: 0.2977
[4/10][1600/5087] loss: 0.3773
[4/10][1700/5087] loss: 0.3005
[4/10][1800/5087] loss: 0.3970
[4/10][1900/5087] loss: 0.3984
[4/10][2000/5087] loss: 0.3856
[4/10][2100/5087] loss: 0.3884
[4/10][2200/5087] loss: 0.4384
[4/10][2300/5087] loss: 0.3926
[4/10][2400/5087] loss: 0.3491
[4/10][2500/5087] loss: 0.3736
[4/10][2600/5087] loss: 0.4227
[4/10][2700/5087] loss: 0.4047
[4/10][2800/5087] loss: 0.4376
[4/10][2900/5087] loss: 0.4545
[4/10][3000/5087] loss: 0.4396
[4/10][3100/5087] loss: 0.3649
[4/10][3200/5087] loss: 0.3189
[4/10][3300/5087] loss: 0.3929
[4/10][3400/5087] loss: 0.4139
[4/10][3500/5087] loss: 0.4088
[4/10][3600/5087] loss: 0.3385
[4/10][3700/5087] loss: 0.4020
[4/10][3800/5087] loss: 0.4581
[4/10][3900/5087] loss: 0.4105
[4/10][4000/5087] loss: 0.4029
[4/10][4100/5087] loss: 0.3645
[4/10][4200/5087] loss: 0.3662
[4/10][4300/5087] loss: 0.4117
[4/10][4400/5087] loss: 0.3620
[4/10][4500/5087] loss: 0.5052
[4/10][4600/5087] loss: 0.3442
[4/10][4700/5087] loss: 0.3428
[4/10][4800/5087] loss: 0.3715
[4/10][4900/5087] loss: 0.3631
[4/10][5000/5087] loss: 0.3467

Test epoch: 4
tensor([0.8968, 0.8433, 0.7892, 0.8223, 0.9793, 0.9525, 0.8577, 0.8138, 0.9022])
tensor(0.8730)

Train epoch: 5
[5/10][0/5087] loss: 0.3781
[5/10][100/5087] loss: 0.3432
[5/10][200/5087] loss: 0.4211
[5/10][300/5087] loss: 0.4016
[5/10][400/5087] loss: 0.3716
[5/10][500/5087] loss: 0.3963
[5/10][600/5087] loss: 0.3865
[5/10][700/5087] loss: 0.3710
[5/10][800/5087] loss: 0.3272
[5/10][900/5087] loss: 0.3737
[5/10][1000/5087] loss: 0.3986
[5/10][1100/5087] loss: 0.4327
[5/10][1200/5087] loss: 0.3712
[5/10][1300/5087] loss: 0.4292
[5/10][1400/5087] loss: 0.3252
[5/10][1500/5087] loss: 0.4162
[5/10][1600/5087] loss: 0.3980
[5/10][1700/5087] loss: 0.3912
[5/10][1800/5087] loss: 0.3797
[5/10][1900/5087] loss: 0.4003
[5/10][2000/5087] loss: 0.3507
[5/10][2100/5087] loss: 0.4000
[5/10][2200/5087] loss: 0.3638
[5/10][2300/5087] loss: 0.3512
[5/10][2400/5087] loss: 0.4348
[5/10][2500/5087] loss: 0.3797
[5/10][2600/5087] loss: 0.3928
[5/10][2700/5087] loss: 0.4306
[5/10][2800/5087] loss: 0.3851
[5/10][2900/5087] loss: 0.3115
[5/10][3000/5087] loss: 0.3767
[5/10][3100/5087] loss: 0.4549
[5/10][3200/5087] loss: 0.3952
[5/10][3300/5087] loss: 0.4365
[5/10][3400/5087] loss: 0.4465
[5/10][3500/5087] loss: 0.3793
[5/10][3600/5087] loss: 0.3490
[5/10][3700/5087] loss: 0.3713
[5/10][3800/5087] loss: 0.3817
[5/10][3900/5087] loss: 0.4050
[5/10][4000/5087] loss: 0.3947
[5/10][4100/5087] loss: 0.4114
[5/10][4200/5087] loss: 0.3514
[5/10][4300/5087] loss: 0.3521
[5/10][4400/5087] loss: 0.3422
[5/10][4500/5087] loss: 0.3661
[5/10][4600/5087] loss: 0.4181
[5/10][4700/5087] loss: 0.3326
[5/10][4800/5087] loss: 0.3590
[5/10][4900/5087] loss: 0.4590
[5/10][5000/5087] loss: 0.3750

Test epoch: 5
tensor([0.8974, 0.8426, 0.7904, 0.8235, 0.9793, 0.9534, 0.8574, 0.8139, 0.9048])
tensor(0.8736)

Train epoch: 6
[6/10][0/5087] loss: 0.3997
[6/10][100/5087] loss: 0.3820
[6/10][200/5087] loss: 0.3661
[6/10][300/5087] loss: 0.4284
[6/10][400/5087] loss: 0.4092
[6/10][500/5087] loss: 0.5018
[6/10][600/5087] loss: 0.3546
[6/10][700/5087] loss: 0.3933
[6/10][800/5087] loss: 0.3834
[6/10][900/5087] loss: 0.3697
[6/10][1000/5087] loss: 0.4205
[6/10][1100/5087] loss: 0.3469
[6/10][1200/5087] loss: 0.3769
[6/10][1300/5087] loss: 0.3143
[6/10][1400/5087] loss: 0.3672
[6/10][1500/5087] loss: 0.4467
[6/10][1600/5087] loss: 0.4197
[6/10][1700/5087] loss: 0.4539
[6/10][1800/5087] loss: 0.3838
[6/10][1900/5087] loss: 0.4208
[6/10][2000/5087] loss: 0.3242
[6/10][2100/5087] loss: 0.3989
[6/10][2200/5087] loss: 0.4282
[6/10][2300/5087] loss: 0.3908
[6/10][2400/5087] loss: 0.4488
[6/10][2500/5087] loss: 0.4178
[6/10][2600/5087] loss: 0.3245
[6/10][2700/5087] loss: 0.4140
[6/10][2800/5087] loss: 0.4372
[6/10][2900/5087] loss: 0.3692
[6/10][3000/5087] loss: 0.4297
[6/10][3100/5087] loss: 0.4294
[6/10][3200/5087] loss: 0.3258
[6/10][3300/5087] loss: 0.3934
[6/10][3400/5087] loss: 0.3827
[6/10][3500/5087] loss: 0.3517
[6/10][3600/5087] loss: 0.3639
[6/10][3700/5087] loss: 0.3524
[6/10][3800/5087] loss: 0.3514
[6/10][3900/5087] loss: 0.4275
[6/10][4000/5087] loss: 0.3568
[6/10][4100/5087] loss: 0.3065
[6/10][4200/5087] loss: 0.3618
[6/10][4300/5087] loss: 0.3923
[6/10][4400/5087] loss: 0.4301
[6/10][4500/5087] loss: 0.4520
[6/10][4600/5087] loss: 0.2889
[6/10][4700/5087] loss: 0.3760
[6/10][4800/5087] loss: 0.4155
[6/10][4900/5087] loss: 0.3421
[6/10][5000/5087] loss: 0.4228

Test epoch: 6
tensor([0.8967, 0.8425, 0.7907, 0.8235, 0.9793, 0.9531, 0.8574, 0.8138, 0.9012])
tensor(0.8731)

Train epoch: 7
[7/10][0/5087] loss: 0.3618
[7/10][100/5087] loss: 0.3593
[7/10][200/5087] loss: 0.3631
[7/10][300/5087] loss: 0.4183
[7/10][400/5087] loss: 0.3947
[7/10][500/5087] loss: 0.4173
[7/10][600/5087] loss: 0.4594
[7/10][700/5087] loss: 0.3772
[7/10][800/5087] loss: 0.4008
[7/10][900/5087] loss: 0.3404
[7/10][1000/5087] loss: 0.3733
[7/10][1100/5087] loss: 0.4852
[7/10][1200/5087] loss: 0.3628
[7/10][1300/5087] loss: 0.3954
[7/10][1400/5087] loss: 0.2978
[7/10][1500/5087] loss: 0.4061
[7/10][1600/5087] loss: 0.4574
[7/10][1700/5087] loss: 0.4042
[7/10][1800/5087] loss: 0.3843
[7/10][1900/5087] loss: 0.4036
[7/10][2000/5087] loss: 0.4025
[7/10][2100/5087] loss: 0.4405
[7/10][2200/5087] loss: 0.3814
[7/10][2300/5087] loss: 0.3548
[7/10][2400/5087] loss: 0.4387
[7/10][2500/5087] loss: 0.3320
[7/10][2600/5087] loss: 0.4216
[7/10][2700/5087] loss: 0.3895
[7/10][2800/5087] loss: 0.3960
[7/10][2900/5087] loss: 0.3624
[7/10][3000/5087] loss: 0.3492
[7/10][3100/5087] loss: 0.4302
[7/10][3200/5087] loss: 0.4305
[7/10][3300/5087] loss: 0.3725
[7/10][3400/5087] loss: 0.3838
[7/10][3500/5087] loss: 0.3903
[7/10][3600/5087] loss: 0.3464
[7/10][3700/5087] loss: 0.3054
[7/10][3800/5087] loss: 0.4053
[7/10][3900/5087] loss: 0.3999
[7/10][4000/5087] loss: 0.3164
[7/10][4100/5087] loss: 0.4325
[7/10][4200/5087] loss: 0.4511
[7/10][4300/5087] loss: 0.4034
[7/10][4400/5087] loss: 0.3490
[7/10][4500/5087] loss: 0.3865
[7/10][4600/5087] loss: 0.3702
[7/10][4700/5087] loss: 0.4057
[7/10][4800/5087] loss: 0.3824
[7/10][4900/5087] loss: 0.3852
[7/10][5000/5087] loss: 0.5024

Test epoch: 7
tensor([0.8961, 0.8428, 0.7916, 0.8233, 0.9793, 0.9528, 0.8584, 0.8135, 0.9046])
tensor(0.8736)

Train epoch: 8
[8/10][0/5087] loss: 0.4029
[8/10][100/5087] loss: 0.4182
[8/10][200/5087] loss: 0.3388
[8/10][300/5087] loss: 0.4610
[8/10][400/5087] loss: 0.3518
[8/10][500/5087] loss: 0.3920
[8/10][600/5087] loss: 0.3614
[8/10][700/5087] loss: 0.3383
[8/10][800/5087] loss: 0.4099
[8/10][900/5087] loss: 0.3862
[8/10][1000/5087] loss: 0.4509
[8/10][1100/5087] loss: 0.3334
[8/10][1200/5087] loss: 0.3790
[8/10][1300/5087] loss: 0.3965
[8/10][1400/5087] loss: 0.4346
[8/10][1500/5087] loss: 0.4278
[8/10][1600/5087] loss: 0.4101
[8/10][1700/5087] loss: 0.3722
[8/10][1800/5087] loss: 0.3702
[8/10][1900/5087] loss: 0.3482
[8/10][2000/5087] loss: 0.3994
[8/10][2100/5087] loss: 0.4325
[8/10][2200/5087] loss: 0.3734
[8/10][2300/5087] loss: 0.4031
[8/10][2400/5087] loss: 0.3996
[8/10][2500/5087] loss: 0.3953
[8/10][2600/5087] loss: 0.3917
[8/10][2700/5087] loss: 0.4342
[8/10][2800/5087] loss: 0.3786
[8/10][2900/5087] loss: 0.4474
[8/10][3000/5087] loss: 0.4109
[8/10][3100/5087] loss: 0.3685
[8/10][3200/5087] loss: 0.4381
[8/10][3300/5087] loss: 0.4444
[8/10][3400/5087] loss: 0.4348
[8/10][3500/5087] loss: 0.4999
[8/10][3600/5087] loss: 0.3778
[8/10][3700/5087] loss: 0.4103
[8/10][3800/5087] loss: 0.5037
[8/10][3900/5087] loss: 0.3533
[8/10][4000/5087] loss: 0.3141
[8/10][4100/5087] loss: 0.3149
[8/10][4200/5087] loss: 0.3680
[8/10][4300/5087] loss: 0.4101
[8/10][4400/5087] loss: 0.3555
[8/10][4500/5087] loss: 0.3910
[8/10][4600/5087] loss: 0.3037
[8/10][4700/5087] loss: 0.4481
[8/10][4800/5087] loss: 0.4053
[8/10][4900/5087] loss: 0.3756
[8/10][5000/5087] loss: 0.4019

Test epoch: 8
tensor([0.8966, 0.8429, 0.7911, 0.8235, 0.9793, 0.9531, 0.8583, 0.8135, 0.9039])
tensor(0.8736)

Train epoch: 9
[9/10][0/5087] loss: 0.3297
[9/10][100/5087] loss: 0.3214
[9/10][200/5087] loss: 0.3284
[9/10][300/5087] loss: 0.3473
[9/10][400/5087] loss: 0.4260
[9/10][500/5087] loss: 0.3170
[9/10][600/5087] loss: 0.4140
[9/10][700/5087] loss: 0.3398
[9/10][800/5087] loss: 0.4310
[9/10][900/5087] loss: 0.3141
[9/10][1000/5087] loss: 0.3530
[9/10][1100/5087] loss: 0.4031
[9/10][1200/5087] loss: 0.4213
[9/10][1300/5087] loss: 0.3156
[9/10][1400/5087] loss: 0.4249
[9/10][1500/5087] loss: 0.3198
[9/10][1600/5087] loss: 0.3565
[9/10][1700/5087] loss: 0.4629
[9/10][1800/5087] loss: 0.4619
[9/10][1900/5087] loss: 0.3730
[9/10][2000/5087] loss: 0.3273
[9/10][2100/5087] loss: 0.3436
[9/10][2200/5087] loss: 0.3683
[9/10][2300/5087] loss: 0.3579
[9/10][2400/5087] loss: 0.5615
[9/10][2500/5087] loss: 0.4063
[9/10][2600/5087] loss: 0.3479
[9/10][2700/5087] loss: 0.4394
[9/10][2800/5087] loss: 0.3738
[9/10][2900/5087] loss: 0.3658
[9/10][3000/5087] loss: 0.4464
[9/10][3100/5087] loss: 0.4482
[9/10][3200/5087] loss: 0.3120
[9/10][3300/5087] loss: 0.3008
[9/10][3400/5087] loss: 0.4407
[9/10][3500/5087] loss: 0.3530
[9/10][3600/5087] loss: 0.4110
[9/10][3700/5087] loss: 0.3345
[9/10][3800/5087] loss: 0.3891
[9/10][3900/5087] loss: 0.4107
[9/10][4000/5087] loss: 0.3959
[9/10][4100/5087] loss: 0.3615
[9/10][4200/5087] loss: 0.3342
[9/10][4300/5087] loss: 0.4202
[9/10][4400/5087] loss: 0.3802
[9/10][4500/5087] loss: 0.4292
[9/10][4600/5087] loss: 0.3561
[9/10][4700/5087] loss: 0.3663
[9/10][4800/5087] loss: 0.3722
[9/10][4900/5087] loss: 0.3242
[9/10][5000/5087] loss: 0.3849

Test epoch: 9
tensor([0.8970, 0.8433, 0.7912, 0.8239, 0.9793, 0.9529, 0.8580, 0.8140, 0.9027])
tensor(0.8736)
