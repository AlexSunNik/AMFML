Namespace(batchSize=32, filename='9tasks_alexnet_5xlr_afrm', gpu='5', lr=0.005, lr_scheduler=None, model='alexnet', nepoch=10, pretrained=False, workers=2)
False
Final Saved Model Path: 9tasks_alexnet_5xlr_afrm

Train epoch: 0
[0/10][0/5087] loss: 1.0020
[0/10][100/5087] loss: 0.6677
[0/10][200/5087] loss: 0.6716
[0/10][300/5087] loss: 0.4712
[0/10][400/5087] loss: 0.5443
[0/10][500/5087] loss: 0.4521
[0/10][600/5087] loss: 0.5584
[0/10][700/5087] loss: 0.5228
[0/10][800/5087] loss: 0.5663
[0/10][900/5087] loss: 0.5336
[0/10][1000/5087] loss: 0.5000
[0/10][1100/5087] loss: 0.5221
[0/10][1200/5087] loss: 0.4490
[0/10][1300/5087] loss: 0.4959
[0/10][1400/5087] loss: 0.4271
[0/10][1500/5087] loss: 0.4445
[0/10][1600/5087] loss: 0.4636
[0/10][1700/5087] loss: 0.4542
[0/10][1800/5087] loss: 0.4783
[0/10][1900/5087] loss: 0.4045
[0/10][2000/5087] loss: 0.3887
[0/10][2100/5087] loss: 0.3692
[0/10][2200/5087] loss: 0.4359
[0/10][2300/5087] loss: 0.4536
[0/10][2400/5087] loss: 0.3943
[0/10][2500/5087] loss: 0.5083
[0/10][2600/5087] loss: 0.4177
[0/10][2700/5087] loss: 0.4176
[0/10][2800/5087] loss: 0.3434
[0/10][2900/5087] loss: 0.4112
[0/10][3000/5087] loss: 0.5473
[0/10][3100/5087] loss: 0.3879
[0/10][3200/5087] loss: 0.4128
[0/10][3300/5087] loss: 0.4640
[0/10][3400/5087] loss: 0.3702
[0/10][3500/5087] loss: 0.3591
[0/10][3600/5087] loss: 0.4368
[0/10][3700/5087] loss: 0.3923
[0/10][3800/5087] loss: 0.4694
[0/10][3900/5087] loss: 0.4158
[0/10][4000/5087] loss: 0.4048
[0/10][4100/5087] loss: 0.5293
[0/10][4200/5087] loss: 0.3492
[0/10][4300/5087] loss: 0.4228
[0/10][4400/5087] loss: 0.3048
[0/10][4500/5087] loss: 0.4772
[0/10][4600/5087] loss: 0.3928
[0/10][4700/5087] loss: 0.3754
[0/10][4800/5087] loss: 0.3833
[0/10][4900/5087] loss: 0.3682
[0/10][5000/5087] loss: 0.4389

Test epoch: 0
tensor([0.9052, 0.8340, 0.7675, 0.8154, 0.9793, 0.9438, 0.8578, 0.7978, 0.8989])
tensor(0.8666)

Train epoch: 1
[1/10][0/5087] loss: 0.4163
[1/10][100/5087] loss: 0.4255
[1/10][200/5087] loss: 0.3843
[1/10][300/5087] loss: 0.3716
[1/10][400/5087] loss: 0.4284
[1/10][500/5087] loss: 0.4175
[1/10][600/5087] loss: 0.3755
[1/10][700/5087] loss: 0.3734
[1/10][800/5087] loss: 0.4258
[1/10][900/5087] loss: 0.4528
[1/10][1000/5087] loss: 0.3947
[1/10][1100/5087] loss: 0.4340
[1/10][1200/5087] loss: 0.4105
[1/10][1300/5087] loss: 0.4239
[1/10][1400/5087] loss: 0.3580
[1/10][1500/5087] loss: 0.3160
[1/10][1600/5087] loss: 0.3226
[1/10][1700/5087] loss: 0.4044
[1/10][1800/5087] loss: 0.4359
[1/10][1900/5087] loss: 0.3843
[1/10][2000/5087] loss: 0.4076
[1/10][2100/5087] loss: 0.4423
[1/10][2200/5087] loss: 0.3723
[1/10][2300/5087] loss: 0.3505
[1/10][2400/5087] loss: 0.3604
[1/10][2500/5087] loss: 0.3763
[1/10][2600/5087] loss: 0.3835
[1/10][2700/5087] loss: 0.3631
[1/10][2800/5087] loss: 0.4157
[1/10][2900/5087] loss: 0.3839
[1/10][3000/5087] loss: 0.4003
[1/10][3100/5087] loss: 0.3686
[1/10][3200/5087] loss: 0.3640
[1/10][3300/5087] loss: 0.3448
[1/10][3400/5087] loss: 0.3948
[1/10][3500/5087] loss: 0.3057
[1/10][3600/5087] loss: 0.4034
[1/10][3700/5087] loss: 0.3806
[1/10][3800/5087] loss: 0.4156
[1/10][3900/5087] loss: 0.2871
[1/10][4000/5087] loss: 0.3483
[1/10][4100/5087] loss: 0.2977
[1/10][4200/5087] loss: 0.3393
[1/10][4300/5087] loss: 0.3869
[1/10][4400/5087] loss: 0.2958
[1/10][4500/5087] loss: 0.3470
[1/10][4600/5087] loss: 0.4305
[1/10][4700/5087] loss: 0.3869
[1/10][4800/5087] loss: 0.3984
[1/10][4900/5087] loss: 0.3238
[1/10][5000/5087] loss: 0.4520

Test epoch: 1
tensor([0.9187, 0.8468, 0.7775, 0.8191, 0.9833, 0.9457, 0.8618, 0.8120, 0.8851])
tensor(0.8722)

Train epoch: 2
[2/10][0/5087] loss: 0.3200
[2/10][100/5087] loss: 0.3963
[2/10][200/5087] loss: 0.3783
[2/10][300/5087] loss: 0.3429
[2/10][400/5087] loss: 0.3931
[2/10][500/5087] loss: 0.3262
[2/10][600/5087] loss: 0.3913
[2/10][700/5087] loss: 0.3894
[2/10][800/5087] loss: 0.3529
[2/10][900/5087] loss: 0.4291
[2/10][1000/5087] loss: 0.4372
[2/10][1100/5087] loss: 0.2774
[2/10][1200/5087] loss: 0.3341
[2/10][1300/5087] loss: 0.4086
[2/10][1400/5087] loss: 0.3498
[2/10][1500/5087] loss: 0.3789
[2/10][1600/5087] loss: 0.3622
[2/10][1700/5087] loss: 0.3836
[2/10][1800/5087] loss: 0.3756
[2/10][1900/5087] loss: 0.3736
[2/10][2000/5087] loss: 0.3131
[2/10][2100/5087] loss: 0.3323
[2/10][2200/5087] loss: 0.3899
[2/10][2300/5087] loss: 0.3202
[2/10][2400/5087] loss: 0.4003
[2/10][2500/5087] loss: 0.3297
[2/10][2600/5087] loss: 0.3190
[2/10][2700/5087] loss: 0.3161
[2/10][2800/5087] loss: 0.3634
[2/10][2900/5087] loss: 0.3178
[2/10][3000/5087] loss: 0.3127
[2/10][3100/5087] loss: 0.3646
[2/10][3200/5087] loss: 0.3491
[2/10][3300/5087] loss: 0.3416
[2/10][3400/5087] loss: 0.3573
[2/10][3500/5087] loss: 0.3563
[2/10][3600/5087] loss: 0.4028
[2/10][3700/5087] loss: 0.3541
[2/10][3800/5087] loss: 0.3766
[2/10][3900/5087] loss: 0.3821
[2/10][4000/5087] loss: 0.3595
[2/10][4100/5087] loss: 0.4111
[2/10][4200/5087] loss: 0.3816
[2/10][4300/5087] loss: 0.4614
[2/10][4400/5087] loss: 0.3122
[2/10][4500/5087] loss: 0.3972
[2/10][4600/5087] loss: 0.4063
[2/10][4700/5087] loss: 0.3664
[2/10][4800/5087] loss: 0.3708
[2/10][4900/5087] loss: 0.3996
[2/10][5000/5087] loss: 0.3000

Test epoch: 2
tensor([0.9250, 0.8547, 0.7978, 0.8341, 0.9865, 0.9553, 0.8658, 0.8180, 0.9113])
tensor(0.8832)

Train epoch: 3
[3/10][0/5087] loss: 0.3457
[3/10][100/5087] loss: 0.3106
[3/10][200/5087] loss: 0.4252
[3/10][300/5087] loss: 0.4056
[3/10][400/5087] loss: 0.3477
[3/10][500/5087] loss: 0.3731
[3/10][600/5087] loss: 0.3511
[3/10][700/5087] loss: 0.3660
[3/10][800/5087] loss: 0.3454
[3/10][900/5087] loss: 0.3621
[3/10][1000/5087] loss: 0.4122
[3/10][1100/5087] loss: 0.3166
[3/10][1200/5087] loss: 0.3415
[3/10][1300/5087] loss: 0.3297
[3/10][1400/5087] loss: 0.3794
[3/10][1500/5087] loss: 0.2770
[3/10][1600/5087] loss: 0.3505
[3/10][1700/5087] loss: 0.3348
[3/10][1800/5087] loss: 0.3324
[3/10][1900/5087] loss: 0.3393
[3/10][2000/5087] loss: 0.3308
[3/10][2100/5087] loss: 0.3583
[3/10][2200/5087] loss: 0.3547
[3/10][2300/5087] loss: 0.4278
[3/10][2400/5087] loss: 0.4356
[3/10][2500/5087] loss: 0.3666
[3/10][2600/5087] loss: 0.3512
[3/10][2700/5087] loss: 0.3800
[3/10][2800/5087] loss: 0.2879
[3/10][2900/5087] loss: 0.3049
[3/10][3000/5087] loss: 0.3738
[3/10][3100/5087] loss: 0.3206
[3/10][3200/5087] loss: 0.3540
[3/10][3300/5087] loss: 0.3036
[3/10][3400/5087] loss: 0.3385
[3/10][3500/5087] loss: 0.3442
[3/10][3600/5087] loss: 0.3668
[3/10][3700/5087] loss: 0.3925
[3/10][3800/5087] loss: 0.3579
[3/10][3900/5087] loss: 0.3544
[3/10][4000/5087] loss: 0.3675
[3/10][4100/5087] loss: 0.2575
[3/10][4200/5087] loss: 0.3443
[3/10][4300/5087] loss: 0.3232
[3/10][4400/5087] loss: 0.3270
[3/10][4500/5087] loss: 0.3718
[3/10][4600/5087] loss: 0.3901
[3/10][4700/5087] loss: 0.4030
[3/10][4800/5087] loss: 0.3096
[3/10][4900/5087] loss: 0.3442
[3/10][5000/5087] loss: 0.2945

Test epoch: 3
tensor([0.9257, 0.8543, 0.7980, 0.8373, 0.9868, 0.9549, 0.8641, 0.8194, 0.9064])
tensor(0.8830)

Train epoch: 4
[4/10][0/5087] loss: 0.3431
[4/10][100/5087] loss: 0.3470
[4/10][200/5087] loss: 0.3509
[4/10][300/5087] loss: 0.2849
[4/10][400/5087] loss: 0.3388
[4/10][500/5087] loss: 0.4169
[4/10][600/5087] loss: 0.3665
[4/10][700/5087] loss: 0.3629
[4/10][800/5087] loss: 0.3715
[4/10][900/5087] loss: 0.3882
[4/10][1000/5087] loss: 0.2913
[4/10][1100/5087] loss: 0.2975
[4/10][1200/5087] loss: 0.3446
[4/10][1300/5087] loss: 0.3354
[4/10][1400/5087] loss: 0.3612
[4/10][1500/5087] loss: 0.3465
[4/10][1600/5087] loss: 0.3529
[4/10][1700/5087] loss: 0.2878
[4/10][1800/5087] loss: 0.4059
[4/10][1900/5087] loss: 0.3388
[4/10][2000/5087] loss: 0.3382
[4/10][2100/5087] loss: 0.4083
[4/10][2200/5087] loss: 0.3307
[4/10][2300/5087] loss: 0.3282
[4/10][2400/5087] loss: 0.3931
[4/10][2500/5087] loss: 0.3437
[4/10][2600/5087] loss: 0.4262
[4/10][2700/5087] loss: 0.3981
[4/10][2800/5087] loss: 0.3521
[4/10][2900/5087] loss: 0.3462
[4/10][3000/5087] loss: 0.3020
[4/10][3100/5087] loss: 0.4547
[4/10][3200/5087] loss: 0.3880
[4/10][3300/5087] loss: 0.3656
[4/10][3400/5087] loss: 0.4500
[4/10][3500/5087] loss: 0.3443
[4/10][3600/5087] loss: 0.4112
[4/10][3700/5087] loss: 0.3609
[4/10][3800/5087] loss: 0.4208
[4/10][3900/5087] loss: 0.3106
[4/10][4000/5087] loss: 0.4580
[4/10][4100/5087] loss: 0.3960
[4/10][4200/5087] loss: 0.3293
[4/10][4300/5087] loss: 0.3865
[4/10][4400/5087] loss: 0.3572
[4/10][4500/5087] loss: 0.3209
[4/10][4600/5087] loss: 0.2880
[4/10][4700/5087] loss: 0.3503
[4/10][4800/5087] loss: 0.3658
[4/10][4900/5087] loss: 0.4353
[4/10][5000/5087] loss: 0.3069

Test epoch: 4
tensor([0.9263, 0.8574, 0.8020, 0.8369, 0.9864, 0.9568, 0.8653, 0.8213, 0.9132])
tensor(0.8851)

Train epoch: 5
[5/10][0/5087] loss: 0.3388
[5/10][100/5087] loss: 0.3650
[5/10][200/5087] loss: 0.3650
[5/10][300/5087] loss: 0.3775
[5/10][400/5087] loss: 0.2931
[5/10][500/5087] loss: 0.3301
[5/10][600/5087] loss: 0.3171
[5/10][700/5087] loss: 0.3901
[5/10][800/5087] loss: 0.4558
[5/10][900/5087] loss: 0.3399
[5/10][1000/5087] loss: 0.3642
[5/10][1100/5087] loss: 0.3257
[5/10][1200/5087] loss: 0.3666
[5/10][1300/5087] loss: 0.3295
[5/10][1400/5087] loss: 0.3612
[5/10][1500/5087] loss: 0.2947
[5/10][1600/5087] loss: 0.2780
[5/10][1700/5087] loss: 0.3388
[5/10][1800/5087] loss: 0.3786
[5/10][1900/5087] loss: 0.2760
[5/10][2000/5087] loss: 0.3537
[5/10][2100/5087] loss: 0.3444
[5/10][2200/5087] loss: 0.3788
[5/10][2300/5087] loss: 0.3791
[5/10][2400/5087] loss: 0.3606
[5/10][2500/5087] loss: 0.3149
[5/10][2600/5087] loss: 0.3859
[5/10][2700/5087] loss: 0.3403
[5/10][2800/5087] loss: 0.3813
[5/10][2900/5087] loss: 0.3538
[5/10][3000/5087] loss: 0.3171
[5/10][3100/5087] loss: 0.3998
[5/10][3200/5087] loss: 0.2900
[5/10][3300/5087] loss: 0.3424
[5/10][3400/5087] loss: 0.3122
[5/10][3500/5087] loss: 0.3832
[5/10][3600/5087] loss: 0.3326
[5/10][3700/5087] loss: 0.3075
[5/10][3800/5087] loss: 0.3758
[5/10][3900/5087] loss: 0.4236
[5/10][4000/5087] loss: 0.3885
[5/10][4100/5087] loss: 0.3085
[5/10][4200/5087] loss: 0.3879
[5/10][4300/5087] loss: 0.2598
[5/10][4400/5087] loss: 0.3769
[5/10][4500/5087] loss: 0.3190
[5/10][4600/5087] loss: 0.3828
[5/10][4700/5087] loss: 0.3345
[5/10][4800/5087] loss: 0.3489
[5/10][4900/5087] loss: 0.3056
[5/10][5000/5087] loss: 0.3276

Test epoch: 5
tensor([0.9270, 0.8579, 0.8033, 0.8370, 0.9869, 0.9569, 0.8646, 0.8221, 0.9120])
tensor(0.8853)

Train epoch: 6
[6/10][0/5087] loss: 0.4338
[6/10][100/5087] loss: 0.3942
[6/10][200/5087] loss: 0.3346
[6/10][300/5087] loss: 0.3272
[6/10][400/5087] loss: 0.2645
[6/10][500/5087] loss: 0.4415
[6/10][600/5087] loss: 0.3491
[6/10][700/5087] loss: 0.3851
[6/10][800/5087] loss: 0.3447
[6/10][900/5087] loss: 0.3522
[6/10][1000/5087] loss: 0.3419
[6/10][1100/5087] loss: 0.3332
[6/10][1200/5087] loss: 0.2898
[6/10][1300/5087] loss: 0.3068
[6/10][1400/5087] loss: 0.2941
[6/10][1500/5087] loss: 0.3023
[6/10][1600/5087] loss: 0.3159
[6/10][1700/5087] loss: 0.3055
[6/10][1800/5087] loss: 0.3316
[6/10][1900/5087] loss: 0.3771
[6/10][2000/5087] loss: 0.3737
[6/10][2100/5087] loss: 0.2931
[6/10][2200/5087] loss: 0.3008
[6/10][2300/5087] loss: 0.3365
[6/10][2400/5087] loss: 0.4272
[6/10][2500/5087] loss: 0.2857
[6/10][2600/5087] loss: 0.3701
[6/10][2700/5087] loss: 0.3742
[6/10][2800/5087] loss: 0.3628
[6/10][2900/5087] loss: 0.2905
[6/10][3000/5087] loss: 0.3088
[6/10][3100/5087] loss: 0.3767
[6/10][3200/5087] loss: 0.3350
[6/10][3300/5087] loss: 0.2999
[6/10][3400/5087] loss: 0.3265
[6/10][3500/5087] loss: 0.3104
[6/10][3600/5087] loss: 0.2911
[6/10][3700/5087] loss: 0.3525
[6/10][3800/5087] loss: 0.3530
[6/10][3900/5087] loss: 0.3503
[6/10][4000/5087] loss: 0.3188
[6/10][4100/5087] loss: 0.2866
[6/10][4200/5087] loss: 0.3408
[6/10][4300/5087] loss: 0.3371
[6/10][4400/5087] loss: 0.2981
[6/10][4500/5087] loss: 0.3402
[6/10][4600/5087] loss: 0.3255
[6/10][4700/5087] loss: 0.3237
[6/10][4800/5087] loss: 0.4036
[6/10][4900/5087] loss: 0.2953
[6/10][5000/5087] loss: 0.4220

Test epoch: 6
tensor([0.9277, 0.8575, 0.8036, 0.8372, 0.9869, 0.9569, 0.8640, 0.8228, 0.9131])
tensor(0.8855)

Train epoch: 7
[7/10][0/5087] loss: 0.3283
[7/10][100/5087] loss: 0.4041
[7/10][200/5087] loss: 0.3831
[7/10][300/5087] loss: 0.3282
[7/10][400/5087] loss: 0.3609
[7/10][500/5087] loss: 0.3971
[7/10][600/5087] loss: 0.2507
[7/10][700/5087] loss: 0.3169
[7/10][800/5087] loss: 0.3825
[7/10][900/5087] loss: 0.2769
[7/10][1000/5087] loss: 0.3078
[7/10][1100/5087] loss: 0.3422
[7/10][1200/5087] loss: 0.3215
[7/10][1300/5087] loss: 0.3012
[7/10][1400/5087] loss: 0.3606
[7/10][1500/5087] loss: 0.3476
[7/10][1600/5087] loss: 0.3095
[7/10][1700/5087] loss: 0.4111
[7/10][1800/5087] loss: 0.3151
[7/10][1900/5087] loss: 0.3885
[7/10][2000/5087] loss: 0.3159
[7/10][2100/5087] loss: 0.2906
[7/10][2200/5087] loss: 0.3333
[7/10][2300/5087] loss: 0.3334
[7/10][2400/5087] loss: 0.3809
[7/10][2500/5087] loss: 0.3561
[7/10][2600/5087] loss: 0.3816
[7/10][2700/5087] loss: 0.3994
[7/10][2800/5087] loss: 0.3676
[7/10][2900/5087] loss: 0.4102
[7/10][3000/5087] loss: 0.3618
[7/10][3100/5087] loss: 0.2879
[7/10][3200/5087] loss: 0.3443
[7/10][3300/5087] loss: 0.3133
[7/10][3400/5087] loss: 0.3846
[7/10][3500/5087] loss: 0.3668
[7/10][3600/5087] loss: 0.3542
[7/10][3700/5087] loss: 0.3063
[7/10][3800/5087] loss: 0.3087
[7/10][3900/5087] loss: 0.3538
[7/10][4000/5087] loss: 0.3244
[7/10][4100/5087] loss: 0.3210
[7/10][4200/5087] loss: 0.3557
[7/10][4300/5087] loss: 0.2985
[7/10][4400/5087] loss: 0.3541
[7/10][4500/5087] loss: 0.3647
[7/10][4600/5087] loss: 0.3456
[7/10][4700/5087] loss: 0.3021
[7/10][4800/5087] loss: 0.4011
[7/10][4900/5087] loss: 0.3280
[7/10][5000/5087] loss: 0.2847

Test epoch: 7
tensor([0.9274, 0.8578, 0.8041, 0.8375, 0.9866, 0.9567, 0.8644, 0.8236, 0.9127])
tensor(0.8856)

Train epoch: 8
[8/10][0/5087] loss: 0.3982
[8/10][100/5087] loss: 0.3973
[8/10][200/5087] loss: 0.3501
[8/10][300/5087] loss: 0.3510
[8/10][400/5087] loss: 0.3987
[8/10][500/5087] loss: 0.3629
[8/10][600/5087] loss: 0.3030
[8/10][700/5087] loss: 0.3693
[8/10][800/5087] loss: 0.3223
[8/10][900/5087] loss: 0.3444
[8/10][1000/5087] loss: 0.3444
[8/10][1100/5087] loss: 0.3753
[8/10][1200/5087] loss: 0.3565
[8/10][1300/5087] loss: 0.3943
[8/10][1400/5087] loss: 0.4325
[8/10][1500/5087] loss: 0.3718
[8/10][1600/5087] loss: 0.3180
[8/10][1700/5087] loss: 0.4034
[8/10][1800/5087] loss: 0.3313
[8/10][1900/5087] loss: 0.3159
[8/10][2000/5087] loss: 0.3170
[8/10][2100/5087] loss: 0.3720
[8/10][2200/5087] loss: 0.3820
[8/10][2300/5087] loss: 0.3228
[8/10][2400/5087] loss: 0.4061
[8/10][2500/5087] loss: 0.3812
[8/10][2600/5087] loss: 0.3191
[8/10][2700/5087] loss: 0.3115
[8/10][2800/5087] loss: 0.4292
[8/10][2900/5087] loss: 0.2980
[8/10][3000/5087] loss: 0.4034
[8/10][3100/5087] loss: 0.3325
[8/10][3200/5087] loss: 0.3081
[8/10][3300/5087] loss: 0.3923
[8/10][3400/5087] loss: 0.4024
[8/10][3500/5087] loss: 0.3321
[8/10][3600/5087] loss: 0.2755
[8/10][3700/5087] loss: 0.3453
[8/10][3800/5087] loss: 0.3558
[8/10][3900/5087] loss: 0.3678
[8/10][4000/5087] loss: 0.3317
[8/10][4100/5087] loss: 0.3364
[8/10][4200/5087] loss: 0.3604
[8/10][4300/5087] loss: 0.3347
[8/10][4400/5087] loss: 0.3747
[8/10][4500/5087] loss: 0.3702
[8/10][4600/5087] loss: 0.3764
[8/10][4700/5087] loss: 0.4288
[8/10][4800/5087] loss: 0.3584
[8/10][4900/5087] loss: 0.3810
[8/10][5000/5087] loss: 0.3497

Test epoch: 8
tensor([0.9270, 0.8582, 0.8034, 0.8372, 0.9868, 0.9570, 0.8643, 0.8240, 0.9133])
tensor(0.8857)

Train epoch: 9
[9/10][0/5087] loss: 0.2856
[9/10][100/5087] loss: 0.3761
[9/10][200/5087] loss: 0.3451
[9/10][300/5087] loss: 0.2795
[9/10][400/5087] loss: 0.3859
[9/10][500/5087] loss: 0.2679
[9/10][600/5087] loss: 0.3574
[9/10][700/5087] loss: 0.4025
[9/10][800/5087] loss: 0.3691
[9/10][900/5087] loss: 0.4078
[9/10][1000/5087] loss: 0.3656
[9/10][1100/5087] loss: 0.3188
[9/10][1200/5087] loss: 0.3418
[9/10][1300/5087] loss: 0.4189
[9/10][1400/5087] loss: 0.3293
[9/10][1500/5087] loss: 0.3847
[9/10][1600/5087] loss: 0.3310
[9/10][1700/5087] loss: 0.3136
[9/10][1800/5087] loss: 0.3377
[9/10][1900/5087] loss: 0.3261
[9/10][2000/5087] loss: 0.3603
[9/10][2100/5087] loss: 0.3723
[9/10][2200/5087] loss: 0.3644
[9/10][2300/5087] loss: 0.2658
[9/10][2400/5087] loss: 0.3712
[9/10][2500/5087] loss: 0.2909
[9/10][2600/5087] loss: 0.4008
[9/10][2700/5087] loss: 0.3967
[9/10][2800/5087] loss: 0.3268
[9/10][2900/5087] loss: 0.3545
[9/10][3000/5087] loss: 0.3222
[9/10][3100/5087] loss: 0.4199
[9/10][3200/5087] loss: 0.3725
[9/10][3300/5087] loss: 0.3163
[9/10][3400/5087] loss: 0.4742
[9/10][3500/5087] loss: 0.3677
[9/10][3600/5087] loss: 0.3755
[9/10][3700/5087] loss: 0.3869
[9/10][3800/5087] loss: 0.3999
[9/10][3900/5087] loss: 0.3478
[9/10][4000/5087] loss: 0.3454
[9/10][4100/5087] loss: 0.2747
[9/10][4200/5087] loss: 0.4037
[9/10][4300/5087] loss: 0.3666
[9/10][4400/5087] loss: 0.3806
[9/10][4500/5087] loss: 0.3355
[9/10][4600/5087] loss: 0.3634
[9/10][4700/5087] loss: 0.3716
[9/10][4800/5087] loss: 0.3173
[9/10][4900/5087] loss: 0.2807
[9/10][5000/5087] loss: 0.3158

Test epoch: 9
tensor([0.9272, 0.8574, 0.8050, 0.8378, 0.9870, 0.9569, 0.8643, 0.8231, 0.9129])
tensor(0.8857)
